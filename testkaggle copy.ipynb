{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "4/4 - 1s - loss: 1.9494 - val_loss: 1.3329\n",
      "Epoch 2/120\n",
      "4/4 - 0s - loss: 1.8336 - val_loss: 1.2554\n",
      "Epoch 3/120\n",
      "4/4 - 0s - loss: 1.7243 - val_loss: 1.1830\n",
      "Epoch 4/120\n",
      "4/4 - 0s - loss: 1.6231 - val_loss: 1.1150\n",
      "Epoch 5/120\n",
      "4/4 - 0s - loss: 1.5221 - val_loss: 1.0530\n",
      "Epoch 6/120\n",
      "4/4 - 0s - loss: 1.4311 - val_loss: 0.9970\n",
      "Epoch 7/120\n",
      "4/4 - 0s - loss: 1.3501 - val_loss: 0.9476\n",
      "Epoch 8/120\n",
      "4/4 - 0s - loss: 1.2698 - val_loss: 0.9047\n",
      "Epoch 9/120\n",
      "4/4 - 0s - loss: 1.1970 - val_loss: 0.8671\n",
      "Epoch 10/120\n",
      "4/4 - 0s - loss: 1.1297 - val_loss: 0.8351\n",
      "Epoch 11/120\n",
      "4/4 - 0s - loss: 1.0694 - val_loss: 0.8099\n",
      "Epoch 12/120\n",
      "4/4 - 0s - loss: 1.0136 - val_loss: 0.7910\n",
      "Epoch 13/120\n",
      "4/4 - 0s - loss: 0.9656 - val_loss: 0.7788\n",
      "Epoch 14/120\n",
      "4/4 - 0s - loss: 0.9249 - val_loss: 0.7731\n",
      "Epoch 15/120\n",
      "4/4 - 0s - loss: 0.8922 - val_loss: 0.7727\n",
      "Epoch 16/120\n",
      "4/4 - 0s - loss: 0.8684 - val_loss: 0.7762\n",
      "Epoch 17/120\n",
      "4/4 - 0s - loss: 0.8494 - val_loss: 0.7800\n",
      "Epoch 18/120\n",
      "4/4 - 0s - loss: 0.8369 - val_loss: 0.7850\n",
      "Epoch 19/120\n",
      "4/4 - 0s - loss: 0.8256 - val_loss: 0.7910\n",
      "Epoch 20/120\n",
      "4/4 - 0s - loss: 0.8161 - val_loss: 0.7946\n",
      "Epoch 21/120\n",
      "4/4 - 0s - loss: 0.8101 - val_loss: 0.7976\n",
      "Epoch 22/120\n",
      "4/4 - 0s - loss: 0.8037 - val_loss: 0.7973\n",
      "Epoch 23/120\n",
      "4/4 - 0s - loss: 0.7980 - val_loss: 0.7946\n",
      "Epoch 24/120\n",
      "4/4 - 0s - loss: 0.7915 - val_loss: 0.7893\n",
      "Epoch 25/120\n",
      "4/4 - 0s - loss: 0.7856 - val_loss: 0.7876\n",
      "Epoch 26/120\n",
      "4/4 - 0s - loss: 0.7805 - val_loss: 0.7866\n",
      "Epoch 27/120\n",
      "4/4 - 0s - loss: 0.7746 - val_loss: 0.7819\n",
      "Epoch 28/120\n",
      "4/4 - 0s - loss: 0.7684 - val_loss: 0.7754\n",
      "Epoch 29/120\n",
      "4/4 - 0s - loss: 0.7624 - val_loss: 0.7705\n",
      "Epoch 30/120\n",
      "4/4 - 0s - loss: 0.7563 - val_loss: 0.7652\n",
      "Epoch 31/120\n",
      "4/4 - 0s - loss: 0.7513 - val_loss: 0.7606\n",
      "Epoch 32/120\n",
      "4/4 - 0s - loss: 0.7467 - val_loss: 0.7524\n",
      "Epoch 33/120\n",
      "4/4 - 0s - loss: 0.7413 - val_loss: 0.7433\n",
      "Epoch 34/120\n",
      "4/4 - 0s - loss: 0.7362 - val_loss: 0.7343\n",
      "Epoch 35/120\n",
      "4/4 - 0s - loss: 0.7314 - val_loss: 0.7290\n",
      "Epoch 36/120\n",
      "4/4 - 0s - loss: 0.7272 - val_loss: 0.7255\n",
      "Epoch 37/120\n",
      "4/4 - 0s - loss: 0.7235 - val_loss: 0.7190\n",
      "Epoch 38/120\n",
      "4/4 - 0s - loss: 0.7198 - val_loss: 0.7158\n",
      "Epoch 39/120\n",
      "4/4 - 0s - loss: 0.7158 - val_loss: 0.7119\n",
      "Epoch 40/120\n",
      "4/4 - 0s - loss: 0.7123 - val_loss: 0.7087\n",
      "Epoch 41/120\n",
      "4/4 - 0s - loss: 0.7084 - val_loss: 0.7070\n",
      "Epoch 42/120\n",
      "4/4 - 0s - loss: 0.7053 - val_loss: 0.7052\n",
      "Epoch 43/120\n",
      "4/4 - 0s - loss: 0.7024 - val_loss: 0.7027\n",
      "Epoch 44/120\n",
      "4/4 - 0s - loss: 0.6996 - val_loss: 0.6986\n",
      "Epoch 45/120\n",
      "4/4 - 0s - loss: 0.6960 - val_loss: 0.6950\n",
      "Epoch 46/120\n",
      "4/4 - 0s - loss: 0.6936 - val_loss: 0.6923\n",
      "Epoch 47/120\n",
      "4/4 - 0s - loss: 0.6910 - val_loss: 0.6893\n",
      "Epoch 48/120\n",
      "4/4 - 0s - loss: 0.6890 - val_loss: 0.6859\n",
      "Epoch 49/120\n",
      "4/4 - 0s - loss: 0.6864 - val_loss: 0.6869\n",
      "Epoch 50/120\n",
      "4/4 - 0s - loss: 0.6848 - val_loss: 0.6867\n",
      "Epoch 51/120\n",
      "4/4 - 0s - loss: 0.6820 - val_loss: 0.6830\n",
      "Epoch 52/120\n",
      "4/4 - 0s - loss: 0.6797 - val_loss: 0.6746\n",
      "Epoch 53/120\n",
      "4/4 - 0s - loss: 0.6766 - val_loss: 0.6673\n",
      "Epoch 54/120\n",
      "4/4 - 0s - loss: 0.6741 - val_loss: 0.6653\n",
      "Epoch 55/120\n",
      "4/4 - 0s - loss: 0.6723 - val_loss: 0.6632\n",
      "Epoch 56/120\n",
      "4/4 - 0s - loss: 0.6703 - val_loss: 0.6599\n",
      "Epoch 57/120\n",
      "4/4 - 0s - loss: 0.6684 - val_loss: 0.6580\n",
      "Epoch 58/120\n",
      "4/4 - 0s - loss: 0.6663 - val_loss: 0.6540\n",
      "Epoch 59/120\n",
      "4/4 - 0s - loss: 0.6650 - val_loss: 0.6509\n",
      "Epoch 60/120\n",
      "4/4 - 0s - loss: 0.6633 - val_loss: 0.6508\n",
      "Epoch 61/120\n",
      "4/4 - 0s - loss: 0.6618 - val_loss: 0.6497\n",
      "Epoch 62/120\n",
      "4/4 - 0s - loss: 0.6604 - val_loss: 0.6498\n",
      "Epoch 63/120\n",
      "4/4 - 0s - loss: 0.6592 - val_loss: 0.6492\n",
      "Epoch 64/120\n",
      "4/4 - 0s - loss: 0.6579 - val_loss: 0.6453\n",
      "Epoch 65/120\n",
      "4/4 - 0s - loss: 0.6568 - val_loss: 0.6391\n",
      "Epoch 66/120\n",
      "4/4 - 0s - loss: 0.6556 - val_loss: 0.6374\n",
      "Epoch 67/120\n",
      "4/4 - 0s - loss: 0.6548 - val_loss: 0.6363\n",
      "Epoch 68/120\n",
      "4/4 - 0s - loss: 0.6539 - val_loss: 0.6358\n",
      "Epoch 69/120\n",
      "4/4 - 0s - loss: 0.6531 - val_loss: 0.6346\n",
      "Epoch 70/120\n",
      "4/4 - 0s - loss: 0.6522 - val_loss: 0.6358\n",
      "Epoch 71/120\n",
      "4/4 - 0s - loss: 0.6514 - val_loss: 0.6332\n",
      "Epoch 72/120\n",
      "4/4 - 0s - loss: 0.6506 - val_loss: 0.6329\n",
      "Epoch 73/120\n",
      "4/4 - 0s - loss: 0.6496 - val_loss: 0.6281\n",
      "Epoch 74/120\n",
      "4/4 - 0s - loss: 0.6485 - val_loss: 0.6255\n",
      "Epoch 75/120\n",
      "4/4 - 0s - loss: 0.6479 - val_loss: 0.6246\n",
      "Epoch 76/120\n",
      "4/4 - 0s - loss: 0.6469 - val_loss: 0.6255\n",
      "Epoch 77/120\n",
      "4/4 - 0s - loss: 0.6459 - val_loss: 0.6246\n",
      "Epoch 78/120\n",
      "4/4 - 0s - loss: 0.6454 - val_loss: 0.6214\n",
      "Epoch 79/120\n",
      "4/4 - 0s - loss: 0.6440 - val_loss: 0.6208\n",
      "Epoch 80/120\n",
      "4/4 - 0s - loss: 0.6434 - val_loss: 0.6235\n",
      "Epoch 81/120\n",
      "4/4 - 0s - loss: 0.6435 - val_loss: 0.6254\n",
      "Epoch 82/120\n",
      "4/4 - 0s - loss: 0.6417 - val_loss: 0.6217\n",
      "Epoch 83/120\n",
      "4/4 - 0s - loss: 0.6409 - val_loss: 0.6183\n",
      "Epoch 84/120\n",
      "4/4 - 0s - loss: 0.6401 - val_loss: 0.6135\n",
      "Epoch 85/120\n",
      "4/4 - 0s - loss: 0.6398 - val_loss: 0.6090\n",
      "Epoch 86/120\n",
      "4/4 - 0s - loss: 0.6395 - val_loss: 0.6074\n",
      "Epoch 87/120\n",
      "4/4 - 0s - loss: 0.6387 - val_loss: 0.6065\n",
      "Epoch 88/120\n",
      "4/4 - 0s - loss: 0.6379 - val_loss: 0.6053\n",
      "Epoch 89/120\n",
      "4/4 - 0s - loss: 0.6370 - val_loss: 0.6019\n",
      "Epoch 90/120\n",
      "4/4 - 0s - loss: 0.6372 - val_loss: 0.5980\n",
      "Epoch 91/120\n",
      "4/4 - 0s - loss: 0.6363 - val_loss: 0.6011\n",
      "Epoch 92/120\n",
      "4/4 - 0s - loss: 0.6363 - val_loss: 0.6085\n",
      "Epoch 93/120\n",
      "4/4 - 0s - loss: 0.6346 - val_loss: 0.6159\n",
      "Epoch 94/120\n",
      "4/4 - 0s - loss: 0.6365 - val_loss: 0.6232\n",
      "Epoch 95/120\n",
      "4/4 - 0s - loss: 0.6348 - val_loss: 0.6196\n",
      "Epoch 96/120\n",
      "4/4 - 0s - loss: 0.6338 - val_loss: 0.6175\n",
      "Epoch 97/120\n",
      "4/4 - 0s - loss: 0.6326 - val_loss: 0.6119\n",
      "Epoch 98/120\n",
      "4/4 - 0s - loss: 0.6315 - val_loss: 0.6050\n",
      "Epoch 99/120\n",
      "4/4 - 0s - loss: 0.6315 - val_loss: 0.6031\n",
      "Epoch 100/120\n",
      "4/4 - 0s - loss: 0.6313 - val_loss: 0.6019\n",
      "Epoch 101/120\n",
      "4/4 - 0s - loss: 0.6311 - val_loss: 0.6005\n",
      "Epoch 102/120\n",
      "4/4 - 0s - loss: 0.6306 - val_loss: 0.5988\n",
      "Epoch 103/120\n",
      "4/4 - 0s - loss: 0.6301 - val_loss: 0.5995\n",
      "Epoch 104/120\n",
      "4/4 - 0s - loss: 0.6290 - val_loss: 0.6059\n",
      "Epoch 105/120\n",
      "4/4 - 0s - loss: 0.6285 - val_loss: 0.6110\n",
      "Epoch 106/120\n",
      "4/4 - 0s - loss: 0.6291 - val_loss: 0.6149\n",
      "Epoch 107/120\n",
      "4/4 - 0s - loss: 0.6288 - val_loss: 0.6140\n",
      "Epoch 108/120\n",
      "4/4 - 0s - loss: 0.6284 - val_loss: 0.6108\n",
      "Epoch 109/120\n",
      "4/4 - 0s - loss: 0.6275 - val_loss: 0.6074\n",
      "Epoch 110/120\n",
      "4/4 - 0s - loss: 0.6270 - val_loss: 0.6042\n",
      "Epoch 111/120\n",
      "4/4 - 0s - loss: 0.6271 - val_loss: 0.5970\n",
      "Epoch 112/120\n",
      "4/4 - 0s - loss: 0.6263 - val_loss: 0.5958\n",
      "Epoch 113/120\n",
      "4/4 - 0s - loss: 0.6264 - val_loss: 0.5995\n",
      "Epoch 114/120\n",
      "4/4 - 0s - loss: 0.6257 - val_loss: 0.5988\n",
      "Epoch 115/120\n",
      "4/4 - 0s - loss: 0.6252 - val_loss: 0.5982\n",
      "Epoch 116/120\n",
      "4/4 - 0s - loss: 0.6250 - val_loss: 0.5988\n",
      "Epoch 117/120\n",
      "4/4 - 0s - loss: 0.6250 - val_loss: 0.6007\n",
      "Epoch 118/120\n",
      "4/4 - 0s - loss: 0.6245 - val_loss: 0.6019\n",
      "Epoch 119/120\n",
      "4/4 - 0s - loss: 0.6240 - val_loss: 0.5970\n",
      "Epoch 120/120\n",
      "4/4 - 0s - loss: 0.6232 - val_loss: 0.5931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a911ad5b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar y preparar el DataFrame\n",
    "df = pd.read_csv('train.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.sort_values(by=['id', 'date'], inplace=True)\n",
    "df.dropna(subset=['valence'], inplace=True)\n",
    "\n",
    "# Función para crear lags\n",
    "def create_lags(df, n_lags):\n",
    "    df_lagged = df.copy()\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        df_lagged[f'valence_lag_{lag}'] = df_lagged.groupby('id')['valence'].shift(lag)\n",
    "    df_lagged.dropna(inplace=True)\n",
    "    return df_lagged\n",
    "\n",
    "# Aplicar la creación de lags\n",
    "n_lags = 7\n",
    "df_lagged = create_lags(df, n_lags)\n",
    "\n",
    "# Excluir columnas no numéricas y la columna objetivo de las características\n",
    "X = df_lagged.drop(['id', 'date', 'valence'] + [f'valence_lag_{i}' for i in range(1, n_lags)], axis=1)\n",
    "y = df_lagged['valence'].values\n",
    "\n",
    "# Escalar las características\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape de X para LSTM\n",
    "X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir el modelo\n",
    "model = Sequential([\n",
    "    LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=120, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- valence\nFeature names seen at fit time, yet now missing:\n- valence_lag_7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Aplicar el mismo procesamiento que al conjunto de entrenamiento\u001b[39;00m\n\u001b[0;32m     11\u001b[0m X_test \u001b[38;5;241m=\u001b[39m test_df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m X_test_scaled\u001b[38;5;241m.\u001b[39mreshape((X_test_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m, X_test_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Realizar predicciones\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Horiz\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Horiz\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:508\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03m    Transformed data.\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    506\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 508\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    517\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n",
      "File \u001b[1;32mc:\\Users\\Horiz\\anaconda3\\lib\\site-packages\\sklearn\\base.py:529\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    466\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    471\u001b[0m ):\n\u001b[0;32m    472\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    533\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Horiz\\anaconda3\\lib\\site-packages\\sklearn\\base.py:462\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    458\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    460\u001b[0m     )\n\u001b[1;32m--> 462\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- valence\nFeature names seen at fit time, yet now missing:\n- valence_lag_7\n"
     ]
    }
   ],
   "source": [
    "# Cargar y preparar el conjunto de prueba\n",
    "test_df = pd.read_csv('test.csv')\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "test_df.sort_values(by=['id', 'date'], inplace=True)\n",
    "test_df['valence'] = 0\n",
    "\n",
    "# Asumiendo que el conjunto de prueba ya ha sido transformado adecuadamente y tiene lags aplicados\n",
    "n_lags = 7\n",
    "df_lagged = create_lags(test_df, n_lags)\n",
    "# Aplicar el mismo procesamiento que al conjunto de entrenamiento\n",
    "X_test = test_df.drop(['id', 'date'], axis=1)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# Realizar predicciones\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Añadir las predicciones al DataFrame de prueba\n",
    "test_df['predicted_valence'] = predictions\n",
    "\n",
    "# Guardar o visualizar las predicciones\n",
    "test_df.to_csv('test_with_predictions.csv', index=False)\n",
    "print(test_df[['id', 'date', 'predicted_valence']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Renombrar las columnas\n",
    "df_merged.rename(columns={'id_kaggle': 'Id', 'valence': 'Category'}, inplace=True)\n",
    "\n",
    "# Paso 2: Convertir y ajustar la columna 'Category'\n",
    "# Convertir 'Category' a entero para eliminar cualquier decimal, luego a string\n",
    "df_merged['Category'] = df_merged['Category'].astype(int).astype(str)\n",
    "# Añadir comillas simples alrededor de los valores de 'Category'\n",
    "df_merged['Category'] = \"'\" + df_merged['Category'] + \"'\"\n",
    "\n",
    "# Paso 3: Seleccionar solo las columnas de interés (Id y Category)\n",
    "df_final = df_merged[['Id', 'Category']]\n",
    "\n",
    "# Paso 4: Guardar el DataFrame en un archivo CSV\n",
    "df_final.to_csv('output_with_quotes.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
